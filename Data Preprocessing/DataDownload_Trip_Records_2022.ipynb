{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "final_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-01: 1045180 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-02: 1106432 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-03: 1268978 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-04: 1247793 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-05: 1292796 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-06: 1264136 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-07: 1215036 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-08: 1211123 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-09: 1240251 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-10: 1370906 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-11: 1252931 rows sampled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_37124\\1704224801.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-12: 1350513 rows sampled.\n",
      "Months included in final_df:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Final data saved to: C:/Users/Dazhou Wu/Desktop/final_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "# 初始化最终的 DataFrame\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# 生成月份列表（从1月到12月）\n",
    "months = [f\"2022-{str(i).zfill(2)}\" for i in range(1, 13)]\n",
    "\n",
    "# 处理每个月的数据\n",
    "for month in months:\n",
    "    try:\n",
    "        # 动态构建文件路径\n",
    "        file_path = f\"C:/Users/Dazhou Wu/Desktop/Mine/master/Fall 24/Data Engineering/Final Project/dataset/fhvhv_tripdata_{month}.parquet\"\n",
    "        \n",
    "        # 读取每个月的数据\n",
    "        df_month = pd.read_parquet(file_path)\n",
    "\n",
    "        # 定义开始和结束日期\n",
    "        start_date = datetime.strptime(f\"{month}-01\", \"%Y-%m-%d\")\n",
    "        _, last_day = calendar.monthrange(start_date.year, start_date.month)\n",
    "        end_date = datetime.strptime(f\"{month}-{last_day}\", \"%Y-%m-%d\")\n",
    "\n",
    "        # 筛选符合条件的数据\n",
    "        filtered_df = df_month[\n",
    "            (df_month['dispatching_base_num'] == 'B03404') &\n",
    "            (df_month['originating_base_num'] == 'B03404') &\n",
    "            (df_month['request_datetime'] >= start_date) &\n",
    "            (df_month['request_datetime'] <= end_date)\n",
    "        ]\n",
    "\n",
    "        # 检查是否为空\n",
    "        if filtered_df.empty:\n",
    "            print(f\"No data found for {month} after filtering. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # 提取日期字段以便按天分组\n",
    "        filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
    "\n",
    "        # 按天分组并随机抽取10%的数据\n",
    "        sampled_filtered_df = (\n",
    "            filtered_df.groupby('date', group_keys=False)\n",
    "            .apply(lambda x: x.sample(frac=0.1, random_state=42))\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # 删除临时列 'date'\n",
    "        sampled_filtered_df = sampled_filtered_df.drop(columns=['date'])\n",
    "\n",
    "        # 将抽样后的数据追加到最终 DataFrame\n",
    "        final_df = pd.concat([final_df, sampled_filtered_df], ignore_index=True)\n",
    "\n",
    "        print(f\"Successfully processed {month}: {len(sampled_filtered_df)} rows sampled.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for {month} not found. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for {month}: {e}\")\n",
    "\n",
    "# 显示最终 DataFrame 中包含的月份\n",
    "print(\"Months included in final_df:\")\n",
    "print(final_df['request_datetime'].dt.month.unique())\n",
    "\n",
    "# 保存最终的 DataFrame 到 CSV 文件\n",
    "output_file = \"C:/Users/Dazhou Wu/Desktop/final_data.csv\"\n",
    "final_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Final data saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14866075"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number = 1350513+1252931+1370906+1240251+1211123+1215036+1264136+1292796+1247793+1268978+1106432+1045180\n",
    "total_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-01: 9015 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-02: 8107 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-03: 9007 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-04: 8716 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-05: 9005 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-06: 8707 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-07: 9014 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-08: 9012 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-09: 8712 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-10: 9002 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-11: 8709 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\1672605366.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2022-12: 9012 rows.\n",
      "Months included in final_df:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Final data saved to: C:/Users/Dazhou Wu/Desktop/final_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "# Recreate the final DataFrame\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# List of months to process (January to December)\n",
    "months = [f\"2022-{str(i).zfill(2)}\" for i in range(1, 13)]\n",
    "\n",
    "# Process each month's data\n",
    "for month in months:\n",
    "    try:\n",
    "        # Construct the file path dynamically for each month's data\n",
    "        file_path = f\"C:/Users/Dazhou Wu/Desktop/Mine/master/Fall 24/Data Engineering/Final Project/dataset/fhvhv_tripdata_{month}.parquet\"\n",
    "\n",
    "        # Load the month's data\n",
    "        df_month = pd.read_parquet(file_path)\n",
    "\n",
    "        # Define start and end date dynamically for filtering\n",
    "        start_date = datetime.strptime(f\"{month}-01\", \"%Y-%m-%d\")\n",
    "        _, last_day = calendar.monthrange(start_date.year, start_date.month)\n",
    "        end_date = datetime.strptime(f\"{month}-{last_day}\", \"%Y-%m-%d\")\n",
    "\n",
    "        # Filter for the required conditions\n",
    "        filtered_df = df_month[\n",
    "            (df_month['dispatching_base_num'] == 'B03404') &\n",
    "            (df_month['originating_base_num'] == 'B03404') &\n",
    "            (df_month['request_datetime'] >= start_date) &\n",
    "            (df_month['request_datetime'] <= end_date)\n",
    "        ]\n",
    "\n",
    "        # Check if filtered DataFrame is empty\n",
    "        if filtered_df.empty:\n",
    "            print(f\"No data found for {month} after filtering. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Extract date for grouping\n",
    "        filtered_df.loc[:, 'date'] = filtered_df['request_datetime'].dt.date\n",
    "\n",
    "        # Group by date and sample 300 rows per day\n",
    "        sampled_filtered_df = (\n",
    "            filtered_df.groupby('date', group_keys=False)\n",
    "            .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # Drop the 'date' column (if not needed)\n",
    "        sampled_filtered_df = sampled_filtered_df.drop(columns=['date'])\n",
    "\n",
    "        # Append the processed data to the final DataFrame\n",
    "        final_df = pd.concat([final_df, sampled_filtered_df], ignore_index=True)\n",
    "\n",
    "        print(f\"Successfully processed {month}: {len(sampled_filtered_df)} rows.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for {month} not found. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for {month}: {e}\")\n",
    "\n",
    "# Display unique months included in the final DataFrame\n",
    "print(\"Months included in final_df:\")\n",
    "print(final_df['request_datetime'].dt.month.unique())\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "output_file = \"C:/Users/Dazhou Wu/Desktop/final_data.csv\"\n",
    "final_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Final data saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 已成功保存到：C:\\Users\\Dazhou Wu\\Downloads\\large_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "downloads_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "output_file = os.path.join(downloads_path, \"large_data.csv\")\n",
    "final_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "print(f\"DataFrame 已成功保存到：{output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the things below are test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-01 00:15:35</td>\n",
       "      <td>2022-06-01 00:17:20</td>\n",
       "      <td>2022-06-01 00:17:41</td>\n",
       "      <td>2022-06-01 00:25:41</td>\n",
       "      <td>234</td>\n",
       "      <td>114</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.36</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-01 00:39:04</td>\n",
       "      <td>2022-06-01 00:40:36</td>\n",
       "      <td>2022-06-01 00:42:37</td>\n",
       "      <td>2022-06-01 00:56:32</td>\n",
       "      <td>161</td>\n",
       "      <td>151</td>\n",
       "      <td>4.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>15.61</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-01 00:27:53</td>\n",
       "      <td>2022-06-01 00:31:34</td>\n",
       "      <td>2022-06-01 00:36:22</td>\n",
       "      <td>2022-06-01 00:45:31</td>\n",
       "      <td>231</td>\n",
       "      <td>87</td>\n",
       "      <td>2.91</td>\n",
       "      <td>...</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.22</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-01 00:48:15</td>\n",
       "      <td>2022-06-01 00:49:38</td>\n",
       "      <td>2022-06-01 00:51:18</td>\n",
       "      <td>2022-06-01 01:11:15</td>\n",
       "      <td>87</td>\n",
       "      <td>225</td>\n",
       "      <td>5.45</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.88</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-01 00:40:17</td>\n",
       "      <td>2022-06-01 00:46:25</td>\n",
       "      <td>2022-06-01 00:47:32</td>\n",
       "      <td>2022-06-01 01:34:28</td>\n",
       "      <td>132</td>\n",
       "      <td>209</td>\n",
       "      <td>20.70</td>\n",
       "      <td>...</td>\n",
       "      <td>5.46</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.86</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17780069</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-30 23:08:42</td>\n",
       "      <td>2022-06-30 23:11:07</td>\n",
       "      <td>2022-06-30 23:11:20</td>\n",
       "      <td>2022-06-30 23:21:06</td>\n",
       "      <td>151</td>\n",
       "      <td>75</td>\n",
       "      <td>1.78</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>9.23</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17780070</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-30 23:20:49</td>\n",
       "      <td>2022-06-30 23:24:23</td>\n",
       "      <td>2022-06-30 23:24:43</td>\n",
       "      <td>2022-06-30 23:38:19</td>\n",
       "      <td>74</td>\n",
       "      <td>224</td>\n",
       "      <td>6.07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>16.23</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17780071</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-30 23:36:13</td>\n",
       "      <td>2022-06-30 23:39:12</td>\n",
       "      <td>2022-06-30 23:39:20</td>\n",
       "      <td>2022-06-30 23:51:10</td>\n",
       "      <td>224</td>\n",
       "      <td>13</td>\n",
       "      <td>4.90</td>\n",
       "      <td>...</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.94</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17780072</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-30 23:50:50</td>\n",
       "      <td>2022-06-30 23:55:11</td>\n",
       "      <td>2022-06-30 23:57:12</td>\n",
       "      <td>2022-07-01 00:07:07</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>18.46</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17780073</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-30 23:02:40</td>\n",
       "      <td>2022-06-30 23:04:58</td>\n",
       "      <td>2022-06-30 23:06:44</td>\n",
       "      <td>2022-06-30 23:26:28</td>\n",
       "      <td>234</td>\n",
       "      <td>48</td>\n",
       "      <td>2.85</td>\n",
       "      <td>...</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>27.27</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13039126 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0                   HV0003               B03404               B03404   \n",
       "1                   HV0003               B03404               B03404   \n",
       "2                   HV0003               B03404               B03404   \n",
       "3                   HV0003               B03404               B03404   \n",
       "6                   HV0003               B03404               B03404   \n",
       "...                    ...                  ...                  ...   \n",
       "17780069            HV0003               B03404               B03404   \n",
       "17780070            HV0003               B03404               B03404   \n",
       "17780071            HV0003               B03404               B03404   \n",
       "17780072            HV0003               B03404               B03404   \n",
       "17780073            HV0003               B03404               B03404   \n",
       "\n",
       "            request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0        2022-06-01 00:15:35 2022-06-01 00:17:20 2022-06-01 00:17:41   \n",
       "1        2022-06-01 00:39:04 2022-06-01 00:40:36 2022-06-01 00:42:37   \n",
       "2        2022-06-01 00:27:53 2022-06-01 00:31:34 2022-06-01 00:36:22   \n",
       "3        2022-06-01 00:48:15 2022-06-01 00:49:38 2022-06-01 00:51:18   \n",
       "6        2022-06-01 00:40:17 2022-06-01 00:46:25 2022-06-01 00:47:32   \n",
       "...                      ...                 ...                 ...   \n",
       "17780069 2022-06-30 23:08:42 2022-06-30 23:11:07 2022-06-30 23:11:20   \n",
       "17780070 2022-06-30 23:20:49 2022-06-30 23:24:23 2022-06-30 23:24:43   \n",
       "17780071 2022-06-30 23:36:13 2022-06-30 23:39:12 2022-06-30 23:39:20   \n",
       "17780072 2022-06-30 23:50:50 2022-06-30 23:55:11 2022-06-30 23:57:12   \n",
       "17780073 2022-06-30 23:02:40 2022-06-30 23:04:58 2022-06-30 23:06:44   \n",
       "\n",
       "            dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  \\\n",
       "0        2022-06-01 00:25:41           234           114        1.50  ...   \n",
       "1        2022-06-01 00:56:32           161           151        4.18  ...   \n",
       "2        2022-06-01 00:45:31           231            87        2.91  ...   \n",
       "3        2022-06-01 01:11:15            87           225        5.45  ...   \n",
       "6        2022-06-01 01:34:28           132           209       20.70  ...   \n",
       "...                      ...           ...           ...         ...  ...   \n",
       "17780069 2022-06-30 23:21:06           151            75        1.78  ...   \n",
       "17780070 2022-06-30 23:38:19            74           224        6.07  ...   \n",
       "17780071 2022-06-30 23:51:10           224            13        4.90  ...   \n",
       "17780072 2022-07-01 00:07:07           231           231        0.53  ...   \n",
       "17780073 2022-06-30 23:26:28           234            48        2.85  ...   \n",
       "\n",
       "          sales_tax  congestion_surcharge  airport_fee  tips  driver_pay  \\\n",
       "0              0.68                  2.75          0.0  1.00        9.36   \n",
       "1              1.81                  2.75          0.0  4.82       15.61   \n",
       "2              1.09                  2.75          0.0  1.00        8.22   \n",
       "3              2.19                  2.75          0.0  0.00       16.88   \n",
       "6              5.46                  2.75          2.5  0.00       48.86   \n",
       "...             ...                   ...          ...   ...         ...   \n",
       "17780069       1.06                  0.00          0.0  3.00        9.23   \n",
       "17780070       1.56                  2.75          0.0  2.24       16.23   \n",
       "17780071       1.59                  2.75          0.0  0.00       13.94   \n",
       "17780072       1.06                  2.75          0.0  3.00       18.46   \n",
       "17780073       2.79                  2.75          0.0  1.00       27.27   \n",
       "\n",
       "          shared_request_flag  shared_match_flag  access_a_ride_flag  \\\n",
       "0                           N                  N                       \n",
       "1                           N                  N                       \n",
       "2                           N                  N                       \n",
       "3                           N                  N                       \n",
       "6                           N                  N                       \n",
       "...                       ...                ...                 ...   \n",
       "17780069                    N                  N                       \n",
       "17780070                    N                  N                       \n",
       "17780071                    N                  N                       \n",
       "17780072                    N                  N                       \n",
       "17780073                    N                  N                       \n",
       "\n",
       "          wav_request_flag wav_match_flag  \n",
       "0                        N              N  \n",
       "1                        N              N  \n",
       "2                        N              N  \n",
       "3                        N              N  \n",
       "6                        N              N  \n",
       "...                    ...            ...  \n",
       "17780069                 N              N  \n",
       "17780070                 N              N  \n",
       "17780071                 N              N  \n",
       "17780072                 N              N  \n",
       "17780073                 N              N  \n",
       "\n",
       "[13039126 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Code for first month\n",
    "file_path = \"C:/Users/Dazhou Wu/Desktop/Mine/master/Fall 24/Data Engineering/Final Project/dataset/fhvhv_tripdata_2022-06.parquet\"\n",
    "\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "df[df['dispatching_base_num'] == 'B03404']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\790140887.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
      "C:\\Users\\Dazhou Wu\\AppData\\Local\\Temp\\ipykernel_34520\\790140887.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:27:29</td>\n",
       "      <td>2022-01-01 00:28:53</td>\n",
       "      <td>2022-01-01 00:29:56</td>\n",
       "      <td>2022-01-01 00:38:33</td>\n",
       "      <td>79</td>\n",
       "      <td>234</td>\n",
       "      <td>1.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 17:34:33</td>\n",
       "      <td>2022-01-01 17:44:02</td>\n",
       "      <td>2022-01-01 17:44:16</td>\n",
       "      <td>2022-01-01 17:52:34</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.35</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 14:47:27</td>\n",
       "      <td>2022-01-01 14:58:33</td>\n",
       "      <td>2022-01-01 14:59:11</td>\n",
       "      <td>2022-01-01 15:18:05</td>\n",
       "      <td>49</td>\n",
       "      <td>133</td>\n",
       "      <td>4.26</td>\n",
       "      <td>...</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.62</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 17:38:27</td>\n",
       "      <td>2022-01-01 17:41:32</td>\n",
       "      <td>2022-01-01 17:42:39</td>\n",
       "      <td>2022-01-01 17:59:30</td>\n",
       "      <td>62</td>\n",
       "      <td>181</td>\n",
       "      <td>3.98</td>\n",
       "      <td>...</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.10</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:45:06</td>\n",
       "      <td>2022-01-01 00:47:01</td>\n",
       "      <td>2022-01-01 00:47:54</td>\n",
       "      <td>2022-01-01 00:59:33</td>\n",
       "      <td>252</td>\n",
       "      <td>56</td>\n",
       "      <td>7.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.88</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9295</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-31 10:36:24</td>\n",
       "      <td>2022-01-31 10:36:34</td>\n",
       "      <td>2022-01-31 10:38:34</td>\n",
       "      <td>2022-01-31 10:51:30</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>5.44</td>\n",
       "      <td>...</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.50</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9296</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-31 22:05:48</td>\n",
       "      <td>2022-01-31 22:13:29</td>\n",
       "      <td>2022-01-31 22:14:02</td>\n",
       "      <td>2022-01-31 22:49:50</td>\n",
       "      <td>170</td>\n",
       "      <td>165</td>\n",
       "      <td>13.33</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.09</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9297</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-31 14:12:30</td>\n",
       "      <td>2022-01-31 14:14:46</td>\n",
       "      <td>2022-01-31 14:15:56</td>\n",
       "      <td>2022-01-31 14:27:55</td>\n",
       "      <td>237</td>\n",
       "      <td>161</td>\n",
       "      <td>1.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.84</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9298</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-31 16:33:19</td>\n",
       "      <td>2022-01-31 16:39:41</td>\n",
       "      <td>2022-01-31 16:39:49</td>\n",
       "      <td>2022-01-31 17:13:30</td>\n",
       "      <td>256</td>\n",
       "      <td>160</td>\n",
       "      <td>6.23</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.12</td>\n",
       "      <td>26.28</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9299</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-31 13:29:13</td>\n",
       "      <td>2022-01-31 13:33:58</td>\n",
       "      <td>2022-01-31 13:35:59</td>\n",
       "      <td>2022-01-31 14:11:45</td>\n",
       "      <td>173</td>\n",
       "      <td>197</td>\n",
       "      <td>9.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.41</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9300 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0               HV0003               B03404               B03404   \n",
       "1               HV0003               B03404               B03404   \n",
       "2               HV0003               B03404               B03404   \n",
       "3               HV0003               B03404               B03404   \n",
       "4               HV0003               B03404               B03404   \n",
       "...                ...                  ...                  ...   \n",
       "9295            HV0003               B03404               B03404   \n",
       "9296            HV0003               B03404               B03404   \n",
       "9297            HV0003               B03404               B03404   \n",
       "9298            HV0003               B03404               B03404   \n",
       "9299            HV0003               B03404               B03404   \n",
       "\n",
       "        request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0    2022-01-01 00:27:29 2022-01-01 00:28:53 2022-01-01 00:29:56   \n",
       "1    2022-01-01 17:34:33 2022-01-01 17:44:02 2022-01-01 17:44:16   \n",
       "2    2022-01-01 14:47:27 2022-01-01 14:58:33 2022-01-01 14:59:11   \n",
       "3    2022-01-01 17:38:27 2022-01-01 17:41:32 2022-01-01 17:42:39   \n",
       "4    2022-01-01 00:45:06 2022-01-01 00:47:01 2022-01-01 00:47:54   \n",
       "...                  ...                 ...                 ...   \n",
       "9295 2022-01-31 10:36:24 2022-01-31 10:36:34 2022-01-31 10:38:34   \n",
       "9296 2022-01-31 22:05:48 2022-01-31 22:13:29 2022-01-31 22:14:02   \n",
       "9297 2022-01-31 14:12:30 2022-01-31 14:14:46 2022-01-31 14:15:56   \n",
       "9298 2022-01-31 16:33:19 2022-01-31 16:39:41 2022-01-31 16:39:49   \n",
       "9299 2022-01-31 13:29:13 2022-01-31 13:33:58 2022-01-31 13:35:59   \n",
       "\n",
       "        dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  \\\n",
       "0    2022-01-01 00:38:33            79           234        1.76  ...   \n",
       "1    2022-01-01 17:52:34            51            51        1.86  ...   \n",
       "2    2022-01-01 15:18:05            49           133        4.26  ...   \n",
       "3    2022-01-01 17:59:30            62           181        3.98  ...   \n",
       "4    2022-01-01 00:59:33           252            56        7.01  ...   \n",
       "...                  ...           ...           ...         ...  ...   \n",
       "9295 2022-01-31 10:51:30           130           132        5.44  ...   \n",
       "9296 2022-01-31 22:49:50           170           165       13.33  ...   \n",
       "9297 2022-01-31 14:27:55           237           161        1.29  ...   \n",
       "9298 2022-01-31 17:13:30           256           160        6.23  ...   \n",
       "9299 2022-01-31 14:11:45           173           197        9.23  ...   \n",
       "\n",
       "      sales_tax  congestion_surcharge  airport_fee  tips  driver_pay  \\\n",
       "0          0.84                  2.75          0.0  0.00        7.52   \n",
       "1          0.96                  0.00          0.0  0.00        7.35   \n",
       "2          1.89                  0.00          0.0  0.00       15.62   \n",
       "3          1.59                  0.00          0.0  0.00       13.10   \n",
       "4          1.76                  0.00          0.0  0.00       18.88   \n",
       "...         ...                   ...          ...   ...         ...   \n",
       "9295       1.63                  0.00          2.5  0.00       12.50   \n",
       "9296       3.32                  2.75          0.0  0.00       33.09   \n",
       "9297       0.90                  2.75          0.0  0.00        7.84   \n",
       "9298       2.82                  0.00          0.0  7.12       26.28   \n",
       "9299       1.97                  0.00          0.0  0.00       29.41   \n",
       "\n",
       "      shared_request_flag  shared_match_flag  access_a_ride_flag  \\\n",
       "0                       N                  N                       \n",
       "1                       N                  N                       \n",
       "2                       N                  N                       \n",
       "3                       N                  N                       \n",
       "4                       N                  N                       \n",
       "...                   ...                ...                 ...   \n",
       "9295                    N                  N                       \n",
       "9296                    N                  N                       \n",
       "9297                    N                  N                       \n",
       "9298                    N                  N                       \n",
       "9299                    N                  N                       \n",
       "\n",
       "      wav_request_flag wav_match_flag  \n",
       "0                    N              N  \n",
       "1                    N              N  \n",
       "2                    N              N  \n",
       "3                    N              N  \n",
       "4                    N              N  \n",
       "...                ...            ...  \n",
       "9295                 N              N  \n",
       "9296                 N              N  \n",
       "9297                 N              N  \n",
       "9298                 N              N  \n",
       "9299                 N              N  \n",
       "\n",
       "[9300 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Code for first month\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 仅保留 request_datetime 在 2022-01-01 到 2022-01-31 范围内的数据\n",
    "filtered_df = df[\n",
    "    (df['dispatching_base_num'] == 'B03404') &\n",
    "    (df['originating_base_num'] == 'B03404') &\n",
    "    (df['request_datetime'] >= '2022-01-01') &\n",
    "    (df['request_datetime'] < '2022-02-01')\n",
    "]\n",
    "\n",
    "# 提取日期用于分组\n",
    "filtered_df['date'] = filtered_df['request_datetime'].dt.date\n",
    "\n",
    "# 每天随机采样 300 行\n",
    "sampled_filtered_df = (\n",
    "    filtered_df.groupby('date')\n",
    "    .apply(lambda x: x.sample(n=300, random_state=42) if len(x) >= 300 else x)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 删除 'date' 列（如果不需要保留）\n",
    "sampled_filtered_df = sampled_filtered_df.drop(columns=['date'])\n",
    "\n",
    "# 显示结果\n",
    "sampled_filtered_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 已成功保存为 CSV 文件，路径：large_data.csv\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
